{
  "cells": [
    {
      "metadata": {
        "_uuid": "728dab1e17bf31dc5e180651af70e4f9d1df9101",
        "_cell_guid": "7e6303a5-7dfc-404b-9088-2f4d2b3a5799",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8a5582ccd7831617ef349be0d0dd5d1da49738b5",
        "_cell_guid": "57fc660b-3ae0-4cc7-a90a-2102b6d6166d",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Import the commmly used libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "103d0ff20a51d5733bcbf88965d9e4f7953eaa54",
        "_cell_guid": "46ff08a0-12cc-4520-a8fd-9373d8ac52b5",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Make sure the ipython notebook will display the figures \n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ba2c78a0ef753dcc55f16edbd7eda371147b5e89",
        "_cell_guid": "138c04fe-1405-46a8-9264-e0f3eaeb3aa2",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Load the data\ndata = pd.read_csv (\"../input/creditcard.csv\")\n\n# Display the first few lines of the credit card data\ndata.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "001f2efe6464fc693e6d8225d4c2e111a862a842",
        "_cell_guid": "7a997289-1a92-44f1-976b-c78b187dfce7",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Display the column names in the data\ndata.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1fbe346ccb8af4cb9c7cf40115de314cdff57c2c",
        "_cell_guid": "a764e64b-d43c-4874-aa0f-953be85c8f4a"
      },
      "cell_type": "markdown",
      "source": "It seems that there are 31 columns in the data"
    },
    {
      "metadata": {
        "_uuid": "f5fde9a41ae4746e1edae1124cd050c03812f2b5",
        "_cell_guid": "9d6a993c-393b-44bf-a2db-596b67068645",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "count_classes = pd.value_counts(data['Class'], sort = True).sort_index()\ncount_classes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5d804ffb762b9cc3c5f2423df579399ce2220418",
        "_cell_guid": "603d82ea-18f2-457c-af76-f5eddc71da65"
      },
      "cell_type": "markdown",
      "source": "Apparently, most data here are in the \"normal\" class, or to say that most transaction data are normal. Only a few transaction data points are conisdered to be abnormal, or fraut. Thus, this is an unbalanced data sets, are therefor challenging for the maching learning prediction, especially for accuracy. Thefore, we need to adjust the amount of normal class data and the abnormal class data, to make them balanaced, by either increasing the amounf of the abnormal class data using the technique called over sampling, or by decreasing the amount of the normal class data using the techque called under sampling. \n\nHere I chose the latter technique by seleting some data points out of normal class data set."
    },
    {
      "metadata": {
        "_uuid": "0c07137b11e3354b70a84bd734d96ea97a27e73e",
        "_cell_guid": "344d5202-61fb-4a95-91de-ab00613d1f61",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# First of all, we need to decide which columns are our features and which is/are variant(s) \n# we need to predict\nfcol = data.ix[:, data.columns != 'Class']\nrcol = data.ix[:, data.columns == 'Class']\n\n# To begin with the data selecting procedure, we need to find out the indices of both the normal\nabnormal_indices = np.array(data[data.Class == 1].index)\nnormal_indices = np.array(data[data.Class == 0].index)\n\n#Find out the number of abnormal data entries \nn_abnormal = len(data[data.Class == 1])\n\n\n# Then, we can randomly select the normal data entries' indices\nrandom_normal_indices = np.random.choice(normal_indices, n_abnormal, replace = False)\nlen(random_normal_indices)\n\n# Now we can merge the selected normal and the original normal data entries\nunder_sample_indices = np.concatenate([abnormal_indices,random_normal_indices])\nunder_sample_data = data.ix[under_sample_indices,:]\n\n# Based on this under samppled data set, we can indicate our feature colummns and result columns\nfcol_under = under_sample_data.ix[:, data.columns != 'Class']\nrcol_under = under_sample_data.ix[:, data.columns == 'Class']\n\n# Double check the data size for both normal and abnormal class in this generated data set\nprint(\"Number of normal transactions\", len(under_sample_data.Class == 0))\nprint(\"Number of abnormal transactions\", len(under_sample_data.Class == 1))\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9bbd50ea0240a5eaaccbacbfe511d220ae1bd08f",
        "_cell_guid": "f8384c34-dd61-4cbf-ab60-652474244861"
      },
      "cell_type": "markdown",
      "source": "Now that we have create a balanced dataset, we can prepare our training and testing datasets by spliting."
    },
    {
      "metadata": {
        "_uuid": "928eafa2bcf62201c47b9fb7cc106eced8709d62",
        "_cell_guid": "a408fce4-e5a6-4036-9a1c-9bb6a3d288a4",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Import the spliting package\nfrom sklearn.cross_validation import train_test_split\n\n# Prepare the training and testing data sets from the original whole data\nf_train, f_test,r_train, r_test = train_test_split(fcol, rcol, test_size = 0.33, random_state = 0)\n\n# Prepare the training and testing data sets from the under sampled data\nf_under_train, f_under_test,r_under_train, r_under_test = train_test_split(fcol_under, rcol_under, test_size = 0.33, random_state = 0) \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "74cf92d57ddc269cb0dbc8b16a79aacb269ba220",
        "_cell_guid": "1a7455fe-f610-403b-84ba-3b1bd7e4c014"
      },
      "cell_type": "markdown",
      "source": "Now we can use the logistic regression classfier to train our data from the original and the under sampled conditions."
    },
    {
      "metadata": {
        "_uuid": "2ef23e69c13e5b0802cf76600d1df11eede66460",
        "_cell_guid": "da977c10-aa43-4b64-b7f3-9c5ffeb0fd10",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Import the logist regression, cross_validation and prediction metrics packages.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import KFold, cross_val_score\nfrom sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "108979b97dbbfd21e159ecbe2126b8f4973f251a",
        "_cell_guid": "094d8340-51cd-47e5-b08c-aa409069acca",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Define a kfold score function to diplay the recall score with different choices of C parameter\ndef Kfold_scores(f_train_data,r_train_data):\n    fold = KFold(len(r_train_data),5,shuffle=False) \n\n    # Different C parameters\n    c_param_range = [0.01,0.1,1,10,100]\n\n    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score'])\n    results_table['C_parameter'] = c_param_range\n\n    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n    j = 0\n    for c_param in c_param_range:\n        print('-------------------------------------------')\n        print('C parameter: ', c_param)\n        print('-------------------------------------------')\n        print('')\n\n        recall_accs = []\n        for iteration, indices in enumerate(fold,start=1):\n\n            # Call the logistic regression model with a certain C parameter\n            lr = LogisticRegression(C = c_param, penalty = 'l1')\n\n            # Use the training data to fit the model. In this case, we use the portion of the fold to train the model\n            # with indices[0]. We then predict on the portion assigned as the 'test cross validation' with indices[1]\n            lr.fit(f_train_data.iloc[indices[0],:],r_train_data.iloc[indices[0],:].values.ravel())\n\n            # Predict values using the test indices in the training data\n            r_pred_undersample = lr.predict(f_train_data.iloc[indices[1],:].values)\n\n            # Calculate the recall score and append it to a list for recall scores representing the current c_parameter\n            recall_acc = recall_score(r_train_data.iloc[indices[1],:].values,r_pred_undersample)\n            recall_accs.append(recall_acc)\n            print('Iteration ', iteration,': recall score = ', recall_acc)\n\n        # The mean value of those recall scores is the metric we want to save and get hold of.\n        results_table.ix[j,'Mean recall score'] = np.mean(recall_accs)\n        j += 1\n        print('')\n        print('Mean recall score ', np.mean(recall_accs))\n        print('')\n\n    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n    \n    # Finally, we can check which C parameter is the best amongst the chosen.\n    print('*********************************************************************************')\n    print('Best model to choose from cross validation is with C parameter = ', best_c)\n    print('*********************************************************************************')\n    \n    return best_c",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5a5e194b77032210af31f164af95310c9e933190",
        "_cell_guid": "61917753-bf5f-43f4-afc2-0d480988d217",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "best_c = Kfold_scores(f_under_train, r_under_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e5fd64c492b42bbf7db17699f03614e31efe1db4",
        "_cell_guid": "7946ee8c-3a32-4ecb-a8d0-dc8f4666df98",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Since we found the best C parameter is 10.0, now that we can try to find out the recall value \n# using the such C \nlr = LogisticRegression(C = best_c, penalty = 'l1')\nlr.fit(f_under_train,r_under_train.values.ravel())\nr_pred_undersample = lr.predict(f_under_test.values)\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(r_under_test,r_pred_undersample)\nnp.set_printoptions(precision=2)\n\nprint(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "627a7c25d205e3a9401050078b7a2b5bd382003f",
        "_cell_guid": "f5088901-2d09-4997-8dea-2629a78ce8b3",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# We can do the similar thing using the original whold data\nlr.fit(f_train,r_train.values.ravel())\nr_pred_Wholesample = lr.predict(f_test.values)\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(r_test,r_pred_Wholesample)\nnp.set_printoptions(precision=2)\n\nprint(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5200ce508f16f1d6ff00c2d7170f69b09f1f4f4b",
        "_cell_guid": "f15a26c7-bcfb-42fb-9f3a-cc6246c7a71f"
      },
      "cell_type": "markdown",
      "source": "Apparently, our under sampling data generating pays off!"
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "name": "python",
      "file_extension": ".py",
      "version": "3.6.3",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "mimetype": "text/x-python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}